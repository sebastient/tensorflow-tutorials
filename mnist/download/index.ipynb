{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Data Download\n",
    "\n",
    "Code: [tensorflow/examples/tutorials/mnist/](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/examples/tutorials/mnist/)\n",
    "\n",
    "The goal of this tutorial is to show how to download the dataset files required\n",
    "for handwritten digit classification using the (classic) MNIST data set.\n",
    "\n",
    "## Tutorial Files\n",
    "\n",
    "This tutorial references the following files:\n",
    "\n",
    "File | Purpose\n",
    "--- | ---\n",
    "[`input_data.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/examples/tutorials/mnist/input_data.py) | The code to download the MNIST dataset for training and evaluation.\n",
    "\n",
    "## Prepare the Data\n",
    "\n",
    "MNIST is a classic problem in machine learning. The problem is to look at\n",
    "greyscale 28x28 pixel images of handwritten digits and determine which digit\n",
    "the image represents, for all the digits from zero to nine.\n",
    "\n",
    "![MNIST Digits](../../../images/mnist_digits.png \"MNIST Digits\")\n",
    "\n",
    "For more information, refer to [Yann LeCun's MNIST page](http://yann.lecun.com/exdb/mnist/)\n",
    "or [Chris Olah's visualizations of MNIST](http://colah.github.io/posts/2014-10-Visualizing-MNIST/).\n",
    "\n",
    "### Download\n",
    "\n",
    "[Yann LeCun's MNIST page](http://yann.lecun.com/exdb/mnist/)\n",
    "also hosts the training and test data for download.\n",
    "\n",
    "File | Purpose\n",
    "--- | ---\n",
    "[`train-images-idx3-ubyte.gz`](http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz) | training set images - 55000 training images, 5000 validation images\n",
    "[`train-labels-idx1-ubyte.gz`](http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz) | training set labels matching the images\n",
    "[`t10k-images-idx3-ubyte.gz`](http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz) | test set images - 10000 images\n",
    "[`t10k-labels-idx1-ubyte.gz`](http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz) | test set labels matching the images\n",
    "\n",
    "In the `input_data.py` file, the `maybe_download()` function will ensure these\n",
    "files are downloaded into a local data folder for training.\n",
    "\n",
    "The folder name is specified in a flag variable at the top of the\n",
    "`fully_connected_feed.py` file and may be changed to fit your needs.\n",
    "\n",
    "### Unpack and Reshape\n",
    "\n",
    "The files themselves are not in any standard image format and are manually\n",
    "unpacked (following the instructions available at the website) by the\n",
    "`extract_images()` and `extract_labels()` functions in `input_data.py`.\n",
    "\n",
    "The image data is extracted into a 2d tensor of: `[image index, pixel index]`\n",
    "where each entry is the intensity value of a specific pixel in a specific\n",
    "image, rescaled from `[0, 255]` to `[-0.5, 0.5]`.  The \"image index\" corresponds\n",
    "to an image in the dataset, counting up from zero to the size of the dataset.\n",
    "And the \"pixel index\" corresponds to a specific pixel in that image, ranging\n",
    "from zero to the number of pixels in the image.\n",
    "\n",
    "The 60000 examples in the `train-*` files are then split into 55000 examples\n",
    "for training and 5000 examples for validation. For all of the 28x28\n",
    "pixel greyscale images in the datasets the image size is 784 and so the output\n",
    "tensor for the training set images is of shape `[55000, 784]`.\n",
    "\n",
    "The label data is extracted into a 1d tensor of: `[image index]`\n",
    "with the class identifier for each example as the value. For the training set\n",
    "labels, this would then be of shape `[55000]`.\n",
    "\n",
    "### DataSet Object\n",
    "\n",
    "The underlying code will download, unpack, and reshape images and labels for\n",
    "the following datasets:\n",
    "\n",
    "Dataset | Purpose\n",
    "--- | ---\n",
    "`data_sets.train` | 55000 images and labels, for primary training.\n",
    "`data_sets.validation` | 5000 images and labels, for iterative validation of training accuracy.\n",
    "`data_sets.test` | 10000 images and labels, for final testing of trained accuracy.\n",
    "\n",
    "The `read_data_sets()` function will return a dictionary with a `DataSet`\n",
    "instance for each of these three sets of data.  The `DataSet.next_batch()`\n",
    "method can be used to fetch a tuple consisting of `batch_size` lists of images\n",
    "and labels to be fed into the running TensorFlow session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_feed, labels_feed = data_set.next_batch(FLAGS.batch_size)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
